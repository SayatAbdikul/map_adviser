import React, { useCallback, useEffect, useRef, useState } from 'react';
import { Send, Car, PersonStanding, Bus, Mic, MicOff } from 'lucide-react';
import { useChatStore } from '@/store/useChatStore';
import { useRouteStore } from '@/store/useRouteStore';
import { chatService } from '@/services/chatService';
import { Button } from '@/components/common/Button';

type TransportMode = 'driving' | 'walking' | 'public_transport';

const TRANSPORT_MODES: {
  mode: TransportMode;
  icon: React.ReactNode;
  label: string;
}[] = [
  { mode: 'driving', icon: <Car size={16} />, label: '–ú–∞—à–∏–Ω–∞' },
  { mode: 'walking', icon: <PersonStanding size={16} />, label: '–ü–µ—à–∫–æ–º' },
  { mode: 'public_transport', icon: <Bus size={16} />, label: '–¢—Ä–∞–Ω—Å–ø–æ—Ä—Ç' },
];

export const ChatInput: React.FC = () => {
  const [text, setText] = useState('');
  const [transportMode, setTransportMode] = useState<TransportMode>('driving');
  const { addMessage, setTyping } = useChatStore();
  const { setRouteResponse, setLoading, setError } = useRouteStore();
  const [isSending, setIsSending] = useState(false);
  const [isRecording, setIsRecording] = useState(false);
  const [speechSupported, setSpeechSupported] = useState(true);
  const recognitionRef = useRef<SpeechRecognition | null>(null);
  const lastSpeechNoticeRef = useRef<{ message: string; at: number } | null>(
    null
  );

  const pushSpeechNotice = useCallback(
    (message: string) => {
      const now = Date.now();
      if (lastSpeechNoticeRef.current) {
        const { message: lastMessage, at } = lastSpeechNoticeRef.current;
        if (lastMessage === message && now - at < 10000) {
          return;
        }
      }

      lastSpeechNoticeRef.current = { message, at: now };
      addMessage({
        id: `speech-${now}`,
        text: message,
        sender: 'bot',
        timestamp: now,
      });
    },
    [addMessage]
  );

  useEffect(() => {
    const SpeechRecognition =
      window.SpeechRecognition || window.webkitSpeechRecognition;

    if (!SpeechRecognition) {
      setSpeechSupported(false);
      return;
    }

    const recognition = new SpeechRecognition();
    recognition.lang = 'ru-RU';
    recognition.continuous = false;
    recognition.interimResults = false;
    recognition.maxAlternatives = 1;

    recognition.onstart = () => {
      setIsRecording(true);
    };

    recognition.onend = () => {
      setIsRecording(false);
    };

    recognition.onerror = event => {
      console.error('Speech recognition error:', event);
      setIsRecording(false);

      const message = (() => {
        switch (event.error) {
          case 'not-allowed':
          case 'service-not-allowed':
            return 'üéôÔ∏è –†–∞–∑—Ä–µ—à–∏—Ç–µ –¥–æ—Å—Ç—É–ø –∫ –º–∏–∫—Ä–æ—Ñ–æ–Ω—É –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞—Ö –±—Ä–∞—É–∑–µ—Ä–∞.';
          case 'no-speech':
            return 'üéôÔ∏è –ù–µ —Ä–∞—Å—Å–ª—ã—à–∞–ª –≥–æ–ª–æ—Å, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â—ë —Ä–∞–∑.';
          case 'audio-capture':
            return 'üéôÔ∏è –ú–∏–∫—Ä–æ—Ñ–æ–Ω –Ω–µ –Ω–∞–π–¥–µ–Ω. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ.';
          case 'network':
            return 'üéôÔ∏è –û—à–∏–±–∫–∞ —Å–µ—Ç–∏ –ø—Ä–∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–∏ —Ä–µ—á–∏.';
          default:
            return 'üéôÔ∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–ø—É—Å—Ç–∏—Ç—å —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ä–µ—á–∏.';
        }
      })();

      pushSpeechNotice(message);
    };

    recognition.onresult = event => {
      const transcript = Array.from(event.results)
        .slice(event.resultIndex)
        .map(result => result[0]?.transcript ?? '')
        .join(' ')
        .trim();

      if (!transcript) return;
      setText(prev => (prev ? `${prev} ${transcript}` : transcript));
    };

    recognitionRef.current = recognition;

    return () => {
      recognition.onresult = null;
      recognition.onerror = null;
      recognition.onend = null;
      recognition.onstart = null;
      recognition.abort();
      recognitionRef.current = null;
    };
  }, [pushSpeechNotice]);

  const handleSend = async (e?: React.FormEvent) => {
    e?.preventDefault();
    if (!text.trim() || isSending) return;

    if (isRecording) {
      recognitionRef.current?.stop();
    }

    const userMsg = text.trim();
    // Capture history BEFORE adding the new user message to avoid duplicating it
    const history = useChatStore.getState().messages.map(m => ({
      role: m.sender === 'bot' ? ('assistant' as const) : ('user' as const),
      content: m.text,
    }));
    const modeLabel =
      TRANSPORT_MODES.find(m => m.mode === transportMode)?.label ||
      transportMode;
    setText('');
    setIsSending(true);
    setLoading(true);

    // Add user message with mode indicator
    addMessage({
      id: Date.now().toString(),
      text: `${userMsg} [${modeLabel}]`,
      sender: 'user',
      timestamp: Date.now(),
    });

    setTyping(true);

    try {
      const response = await chatService.sendMessage(
        userMsg,
        transportMode,
        history
      );

      // Add bot response message
      addMessage(response.message);

      // Update route store with route data if available
      if (response.routeData) {
        setRouteResponse(response.routeData);
        setError(null);
      } else {
        setRouteResponse(null);
        if (response.message.text.startsWith('‚ùå')) {
          setError(response.message.text);
        } else {
          setError(null);
        }
      }
    } catch (error) {
      console.error('Failed to send message:', error);
      setError(error instanceof Error ? error.message : 'Unknown error');
      addMessage({
        id: Date.now().toString(),
        text: '‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ –∑–∞–ø—Ä–æ—Å–∞.',
        sender: 'bot',
        timestamp: Date.now(),
      });
    } finally {
      setTyping(false);
      setIsSending(false);
      setLoading(false);
    }
  };

  const handleToggleRecording = () => {
    if (isSending) return;
    if (!speechSupported) {
      pushSpeechNotice(
        'üéôÔ∏è –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ä–µ—á–∏ –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è –≤ —ç—Ç–æ–º –±—Ä–∞—É–∑–µ—Ä–µ.'
      );
      return;
    }
    const recognition = recognitionRef.current;
    if (!recognition) return;

    if (isRecording) {
      recognition.stop();
      return;
    }

    try {
      recognition.start();
    } catch (error) {
      console.error('Failed to start speech recognition:', error);
      setIsRecording(false);
      pushSpeechNotice('üéôÔ∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–ø—É—Å—Ç–∏—Ç—å —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ä–µ—á–∏.');
    }
  };

  return (
    <div className="p-3 app-surface border-t app-border">
      {/* Transport Mode Selector */}
      <div className="flex items-center gap-1 mb-2">
        {TRANSPORT_MODES.map(({ mode, icon, label }) => (
          <button
            key={mode}
            type="button"
            onClick={() => setTransportMode(mode)}
            className={`flex items-center gap-1.5 px-3 py-1.5 rounded-full text-sm font-medium transition-colors ${
              transportMode === mode
                ? 'bg-[color:var(--app-accent)] text-[color:var(--app-accent-contrast)]'
                : 'bg-[color:var(--app-surface-2)] text-[color:var(--app-muted)] hover:bg-[color:var(--app-surface-3)]'
            }`}
          >
            {icon}
            <span>{label}</span>
          </button>
        ))}
      </div>

      {/* Input Form */}
      <form onSubmit={handleSend} className="flex items-center gap-2">
        <input
          type="text"
          className="flex-1 bg-[color:var(--app-surface-2)] text-[color:var(--app-text)] placeholder-[color:var(--app-muted)] border-0 rounded-full px-4 py-2 focus:ring-2 focus:ring-[color:var(--app-ring)] focus:bg-[color:var(--app-surface)] transition-colors"
          placeholder="–í–≤–µ–¥–∏—Ç–µ –º–∞—Ä—à—Ä—É—Ç, –Ω–∞–ø—Ä–∏–º–µ—Ä: –æ—Ç –ë–∞–π—Ç–µ—Ä–µ–∫–∞ –¥–æ EXPO..."
          value={text}
          onChange={e => setText(e.target.value)}
        />
        <Button
          type="button"
          variant={isRecording ? 'danger' : 'secondary'}
          size="sm"
          disabled={isSending}
          aria-disabled={!speechSupported}
          onClick={handleToggleRecording}
          aria-pressed={isRecording}
          title={
            !speechSupported
              ? '–†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ä–µ—á–∏ –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è'
              : isRecording
                ? '–û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∑–∞–ø–∏—Å—å'
                : '–ì–æ–≤–æ—Ä–∏—Ç–µ –¥–ª—è –≤–≤–æ–¥–∞'
          }
          className={`rounded-full w-10 h-10 p-0 flex-shrink-0 ${
            speechSupported ? '' : 'opacity-60 cursor-not-allowed'
          }`}
        >
          {speechSupported ? <Mic size={18} /> : <MicOff size={18} />}
        </Button>
        <Button
          type="submit"
          variant="primary"
          size="sm"
          disabled={!text.trim() || isSending}
          className="rounded-full w-10 h-10 p-0 flex-shrink-0"
        >
          <Send size={18} className={text.trim() ? 'ml-1' : ''} />
        </Button>
      </form>
    </div>
  );
};
